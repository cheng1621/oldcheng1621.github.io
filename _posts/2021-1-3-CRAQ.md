---
layout: post
title:  "CRAQ Note"
date: 2021-01-06 21:32:10 +0800
categories: [Distributed System]
tags: [Distributed System,CRAQ]
---

# Abstract.
Many systems sacrifice consistency property for greater availability and higher throughput. CRAQ can maintain strong consistency while improving throughput.  

# Introduction.
Object-based system : supported by key-value system. Easy to modify, cheap to provide consistency guarantees.  
`chain replication` : chain head handles write operations and tail handles read operatons. (guarantee consistency).  
Problems: if all reads go to one node, the node would become hotspots.  
  
### CRAQ
***(that part I still don't know well)***.
dividing read operations all over nodes in a chain and keep eventual-consistency at the same time.  

# Basic System Model.
### Interface and Consistency Model
two APIs : write and read.  
write and read are in some specific sequential order to guarantee ***strong consistency***.   

### Chain Replication.
replicating data across mutiple nodes and keep strong consistency at the same time.  
Read can only get the committed value where write propogate to the tail of the chain.   
Advantage: strong consistency. Disadvantage: reduce read throughput to that of a single node, instead of scale out with chain size.  

### Chain Replication with apportioned Queries.
Read operations can be at any nodes. When writes propogate along the chain, the version is marked ***dirty*** until tail commit it. Version could be marked ***clean*** when the acknowledge go back up the chain. When a read operation comes at a node where the version is dirty, the node could ask tail node for the latest version. all in all, the latest committed value is returned always.  
Could be applied in two scenarios: 
1. Read-mostly Workloads.
2. Write-heavy Workloads. Guarantee version queries is light-weight than full reads.

### Consistency Models on CRAQ.
1. strong consistency.***(listed above)***  
2. Eventual consistency.  
3. Eventual consistency with maximum-bounded inconsistency.  

### Failure Recovery in CRAQ.
prodecessor takes over the tail, successor takes over the head.   

# Scaling CRAQ
### Chain Placement Strategies.
note: Popular objects might need to be heavily replicated while unpopular ones can be scarce.  
two identifiers: ***chain identifier*** and ***key identifier***  
chain identifer determines which nodes in CRAQ will store keys within the chain.  
key identifier determines provides unique naming within the chain.  

### CRAQ within a Datacenter.
place chains within a datacenter and map all the chain identifier to single head node.  

### CRAQ across multiple datacenters.
### Zookeeper Coordination Service.
Zookeeper: CRAQ nodes should receive a notification when nodes are added or deleted in the group.  
Problem: Placing multiple ZooKeeper nodes within a single datacenter improves Zookeeper read scalability within that datacenter, but at the cost of wide-area performance  
each datacenter can contain his own local Zookeeper instance of multiple nodes.  

# Extensions.
### mini-transaction on CRAQ.
Key extension supports transactional operations.  
##### Single-key Operation.
three operations: `Prepend/Append`, `Increment/Decrement` and `Test-and-Set`.  
for `Prepend/append` and `Increment/Decrement`, the head can apply the operations to latest version even if the version is dirty.  
for `Test-and-Set`, the request is rejected if the version is not matched.  
if the requests are frequent, the head can buffer the requests and batch the updates. ***the overhead is expensive***.  

##### Single-chain Operation.
A optimistic two-phase commit protocol. A linear address is being implemented in several nodes (fault-tolerance). if the address is locked, the protocol commit.  
##### Multi-Chain Operations.
the chain head can lock any keys involved in the minitransaction.   

### Lowering Write latency with Multicast.
Multicast can improve write performance.   

***(at this time, I don't care about the Implementation and Evaluation of CRAQ)***
# Management and Implementation.

