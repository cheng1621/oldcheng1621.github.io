---
layout: post
title:  "6.824 (假设能拿到offer的项目）"
date: 2021-06-01 19:10:10 +0800
categories: [Distributed System]
tags: [Distributed System,Raft]
---

### 1.先来个自我介绍吧。
嗯嗯，我之前写过一个基于LLVM的小型编译器，写过一个小型操作系统的kernel，最近写过一个有关分布式系统的，这个分布式系统实际上就是一个可容错性的分布式key/value数据库，支持动态扩容，负载均衡，线性一致性，这个一致性是基于raft共识算法，嗯，raft 就是为了在不同的服务器保持一致性的一种算法。这个数据库支持一定的容错，就是一个服务器崩了，另一个服务器马上就能取代原来的服务器开始工作。(说了那么多分布式你要是还问那个kernel项目，你真是头子)

### 2.你为什么做那个分布式项目
任何服务器都有可能在没有通知的情况下死机，并且一台服务器处理会造成超载，出现故障后可容错性和可恢复性差。所以分布式是非常有必要的。(不做的话难道等挂科？)

### 3.那你简单介绍一下那个项目吧
嗯，这个项目是一个key/value数据库，支持`动态扩缩容`,`负载均衡`,`线性一致性`, `可容错` 和 `可恢复`。  
首先先说说`负载均衡`:   
对数据库进行碎片化，通过对key 哈希取模确定虚拟碎片节点，再由虚拟服务器确定物理服务器。  
![Picture1](https://raw.githubusercontent.com/cheng1621/HelloMike.github.io/master/assets/img/sample/fault_tolerent_system_1.png)  

再说说`动态扩缩容`:  
假如说有10个虚拟节点，原来有3个物理节点，考虑负载均衡的话，那他们分别处理的虚拟节点数是3，4，3. 但是如果第四个物理节点加进来以后，那就是2，2，3，3，也就是第二个节点要分两个给新的物理节点。删除也是同样的道理。 增加和删除的操作靠一个controller来进行管理，controller本身也是一个raft集群。
![Picture2](https://raw.githubusercontent.com/cheng1621/HelloMike.github.io/master/assets/img/sample/fault_tolerant_system_2.png) 

`线性一致性`:  
通过Raft共识算法实现线性一致性。
例如： `a:1` --> `get(a)` --> `put(a : 2)` --> `get(a)`. 前一个get读到1， 后一个get读到2. 

`可容错`:  
每个节点都对应着由一组服务器，一个节点死机后由另一个服务器代替工作，服务器之间的一致性由raft管理。  

`可恢复`:  
快照 和 raft 日志回放。  

### 4.既然你提到raft,那你简单说一下raft的选举过程。（就猜到你问这个）
嗯，raft 有三种状态，`leader`, `candidate` 和 `follower`. 如果follower超过过期时间没有接收到来自leader的心跳，那它就会变成candidate，同时发起选举，有两种情况它能获取选票。1. candidate的最后一个log的term 比 follower的 log term 要高。   2. term 相同的情况下，如果candidate 的 log 比follower 要长的话，它也能获得选票。 如果它获得大部人的选票的时候，它就变成了leader了，然后向其他的follower发送心跳。如果它没有收到足够的选票，他自己的term就会+1,然后发起新一轮的选票，或者他收到了来自leader的心跳重新变成follower.

### 5.能说一下脑裂吗。
脑裂就是假设有3个服务器，一开始都是follower的状态，但是他们基本同时变成了candidate，这种情况下是选不出leader的，一个简单的解决方法就是给每一个follower设置一个随机的过期时间。虽然同时变成candidate的这种情况依然存在，但是因为他们的过期时间是随机的，所以他们肯定在将来的某个term会选举出一个leader

### 6.可容错和可恢复是怎么做的。
可容错实际上就是raft，因为同一个集群中，他们始终能保持这一致性，一个服务器崩了，另一个服务器马上就选出新的leader开始新一轮的工作。
可恢复就是，当log日志过大时，进行一个快照的操作，如果这个服务器重启了，就直接启用快照，然后log回放就可以了

### 7.你这个负载均衡是怎么做的。
负载均衡就是对client的请求hash取模，根据虚拟节点对物理节点的映射找到对应的物理节点。

### 8.你提到hash取模，有没有听说过一致性哈希算法。 （还好我了解过）
嗯，一致性哈希算法就是为了解决hash取模的局限性的，如果用hash取模，节点的增加或者减少会导致大量映射的改变，而一致性哈希算法就是为了尽可能少地改变映射关系。

### 9.那你这个项目有什么难点吗
难点吧，有几个
1. 确保各种可靠性。  
首先在扩容的时候，因为节点的增加要把旧节点的数据同步到新节点，并停止旧节点的服务，假设一种情况：一个client发送append请求后，节点才停止服务，但此时append请求已经到达raft状态机等待commit, 正常来说这个put请求就是无效的，所以就算是commit过了也不能更改k/v数据库中的消息，我的办法就是在commit过后再判断一次节点的服务是否在线，如果不在线就不要修改了。  
在raft 选举中也是，如果candidate 得到了大量的选票， 但此时他已经不是candidate 的状态了，此时就算是获得了足够的选票也不能变为leader，因为从Candidate 变为 follower说明集群中的某个服务器的term 肯定比自己高。  
leader发送心跳的时候也是，发送之前和发送之后如果发生了状态的改变，也要当前的更改操作。  
在这个项目中，需要大量的状态检测来确保每一个操作都是可靠的，因为无法控制哪个goroutine先被运行。

2. 分区中，例如一个leader死机了一段时间又重新加入到集群中，这个leader就会向其他的集群发送心跳和日志复制等消息，但显然这些都是无效的信息，follower不能对心跳作出反应，当然这个就比较好解决了，因为死机后那个leader的term一定比新leader的term低，可以根据这个term来加以判断。

### 10.听你这么说也不是很难啊。（哥，我感觉真的挺难）
### 11.那你又做什么优化吗。 
1. 扩容的时候，配置更新的时候，一开始我的做法就是锁住整个服务，等到配置更新完毕后再释放，如一开始，group1 负责 `分区1，分区2，分区3`,但是新的配置是将 分区1 的数据转移到 group2, 这时候就没必要锁住整个服务了，分区2 和 分区3 还是能正常接收client的请求的。
2. 配置的时候，尽可能少得改变当前配置，如前面所说`3,4,3` -> `2,2,3,3` 直接从4中划分两个节点出来就可以了，没必要重新洗牌再分配。
3. 转移分区的后，把旧节点中停止服务的分区数据清理掉，避免造成空间的浪费。  
4. 对 client 重复的请求直接返回数据。  
下面的两个是raft 状态机的优化。  
5. 假设一台服务器死机的时间过长，当它重新启动的时候，它会接收snapshot 和 log 回放，假设如下情况：
![Picture3](https://raw.githubusercontent.com/cheng1621/HelloMike.github.io/master/assets/img/sample/fault_tolerant_system_4.png)  
第一张图的情况是当一个服务器重启后再连上的时候发生的，根据raft，leader每次都把log递减，就是：  
```
1st.    log[]   index:1000  
2nd.    log[6]  index:999  
3rd.    log[6,6]index:998.  
直到找到发生冲突的第一个log，在这种情况下就需要发送995次心跳。  
```  
第二张图是当raft集群是在网络不稳定的产生，raft内部的leader不断变换。 在这种情况下也需要8次的心跳。  
优化：  
第一张图：
当follower接收到leader的心跳后，因为follower不存在index为1000的log， 所以直接返回自己的log 长度，告诉leader从这里开始发送，在这种情况下，心跳的次数变成了3次。  
第二张图：
term:6 != term :3. follower 直接返回term 为3 的最左边的序号，心跳的次数为：3.  
这个优化是在尽可能少地减少网络请求的情况下找到产生冲突的那个log.

5. 一开始日志的复制完全依赖于心跳，而心跳的速度不宜过快，大概为 200ms 一次，但是就算是上面的那两种情况下也需要 600ms 才能完成日志的复制。  
优化：当接收到来自client的请求后马上发送心跳，同时设置心跳过期时间，避免重发。这样的结果就是日志的同步更快了，缺点就是网络请求的增加。导致的问题就是：  
假设raft 分别接收到两个请求：request1 和 request 2.  但是假如request2 比request1 先处理，不加状态检测的话，就会导致刚加进来的log意外地丢失，所以还是要在操作之前判断这种情况是否发生。 优化结果就是：一开始一个请求平均需要 120ms -> 到9ms.  (强不强。!_!)

### 12.End.
